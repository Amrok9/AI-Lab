{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Text Classifier**\n",
        "\n",
        " **Goal**: Build a spam detector using the Multinomial Naive Bayes algorithm on a text dataset."
      ],
      "metadata": {
        "id": "ES3Koq4gSZfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**installing the dataset**"
      ],
      "metadata": {
        "id": "nktNaEtaSm_3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuX-LRCpPJtt",
        "outputId": "36ba743a-e3b2-4ea9-ee83-2865a398e0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "uciml_sms_spam_collection_dataset_path = kagglehub.dataset_download('uciml/sms-spam-collection-dataset')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Required Libraries**"
      ],
      "metadata": {
        "id": "fF4tMtyDSpIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn matplotlib seaborn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmHVTYojP_NN",
        "outputId": "aace4b92-cc78-4a15-ebb8-366cd96e2fef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the SMS Spam Dataset**"
      ],
      "metadata": {
        "id": "fhlTcIy-Svqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\",encoding='latin1')[['v1', 'v2']]\n",
        "\n",
        "# rename columns\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Preview the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E5qwLIpQGjC",
        "outputId": "93299f75-5a39-4386-f47d-5d780d58d1c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess the Data**"
      ],
      "metadata": {
        "id": "xKEY3SRMSy9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to binary: spam = 1, ham = 0\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "# Check class balance\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3s3RtxXQTQr",
        "outputId": "fcc2a329-b871-45b9-c5ab-223387e64dda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data into Training and Test Sets**"
      ],
      "metadata": {
        "id": "yc-NhzfzS2qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['message']  # Text data\n",
        "y = df['label']    # Spam or ham\n",
        "\n",
        "# Split into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "QFckk0QERZC-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Text to Vectors (TF-IDF)**"
      ],
      "metadata": {
        "id": "GsFUoybyS5vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "# Fit on training data and transform both train and test\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "lsNj_VCOR_wc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "ByonI1_-S8R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test_vec)"
      ],
      "metadata": {
        "id": "HvMaCTE5SB49"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**"
      ],
      "metadata": {
        "id": "35DHBrYaS--6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "# Confusion matrix\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "# Classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwIM18FzSE-X",
        "outputId": "a22edfa0-b238-4f7e-aae4-2465594f689a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9668161434977578\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 37 113]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.75      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.96      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "In this project, we built a machine learning model to classify SMS messages as either Spam or Ham (Not Spam) using the Multinomial Naive Bayes algorithm. The raw message text was first converted into numerical features using TF-IDF Vectorization, which measures the importance of words while ignoring common stopwords.\n",
        "\n",
        "After training the model on 80% of the data, we evaluated it on the remaining 20%. **The results showed:**\n",
        "* Accuracy: 96.7%\n",
        "* Precision (Spam): 100% (no false positives)\n",
        "* Recall (Spam): 75% (some spam was missed)\n",
        "* F1 Score (Spam): 86%\n",
        "\n",
        "**Key Insights:**\n",
        "\n",
        "The model accurately detects ham messages with 100% recall.\n",
        "It missed some spam messages, which lowered the spam recall to 75%.\n",
        "\n",
        "This trade-off (no false spam predictions, but some missed spam) can be tuned by adjusting the decision threshold or trying other models like SVM or ensemble methods."
      ],
      "metadata": {
        "id": "qKhcV4IBTDjj"
      }
    }
  ]
}